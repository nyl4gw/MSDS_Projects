{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file should help navigate the folders in the \"nmicp\" project space on Rivanna\n",
    "## Updated as of 05/10/22\n",
    "## File location: /project/nmicp\n",
    "## Metadata documentation: https://nmicp.github.io/ebay_api/intro.html\n",
    "---\n",
    "## Types of File Extensions\n",
    "\n",
    "### .ipynb\n",
    "This file type is a notebook file for python. This allows you to run code and to markdown the page to make comments and structure. \n",
    "\n",
    "- To run each cell click \"SHIFT ENTER\" or press the play button (arrow pointing to the right) on the top bar. \n",
    "\n",
    "- \"#\" in python are comments. You can use \"#\" to comment out lines of code or to make remarks.\n",
    "\n",
    "### .csv\n",
    "A delimited text file separated by commas by default (comma seperated values). You can download these files to upload to whatever software you are using. Data from this project can be downloaded as a csv file either through AccessingData.ipynb or through the datasette module.\n",
    "\n",
    "### .py\n",
    "Programming file for python. This can be written in a text editor, and allows all the code in the script to run at once. Our main script for data collection, and our script for category lists exist as this type of file. \n",
    "\n",
    "### .out\n",
    "This file type stores executable code. This is automatically generated from the slurm script, and can stores information if any errors occur. You should not have to edit this directly. \n",
    "\n",
    "### .slurm\n",
    "This file type is where we include parameters of running the automated script. More information of specific parameters are included in the metadata documentation. \n",
    "\n",
    "### .db\n",
    "The database that is being updated everynight when new data ia collected. You will not be able to click and open this file, but instead access it contents through the datasette module (instructions in book) or through code.\n",
    "\n",
    "---\n",
    "## Files\n",
    "### navigation.ipynb\n",
    "This file should contain a high level overview of what each file contains.\n",
    "\n",
    "### categories_capstone.csv\n",
    "A csv file of the categories and category ids of the original data pipeline constructed by the NMICP capstone team.\n",
    "\n",
    "### CategoryList_Input.py\n",
    "Python script of categories in data collection process. This file can be edited to include/remove category ids from eBay. eBay category IDs can be found here: https://pages.ebay.com/sellerinformation/news/fallupdate16/category-and-item.html. You can select specific categories to see a full list of category IDs. \n",
    "\n",
    "The main python script (eBay_datacollection.py) is written in a way that collects data that maximizes the number of observations. If you **add** a category ID, it should not affect the data pipeline and collection. A maximum number of category IDs in this list should be 50. \n",
    "\n",
    "**Changing Categories**\n",
    "\n",
    "The pipeline is currently set up to extract 1 page (100 listings) from each category. The call limit is 5,000 calls per day, so the maximum number of category ids should be 50. Not all these categories will have 100 new listings posted daily, so that is why our average daily rate is somewhere between 2000-3000. However, if we increase the number of category id’s to, for example, 55 and all these categories have 100 new items, then the API connection will crash due to the call limit exceeding 5,000. If researchers are interested in fewer categories, they will need to edit line 72 in eBay_datacollection.py (this is not advised, but can be completed if necessary) to optimize the number of listings captured. \n",
    "\n",
    "Currently **line 72** (in python script existing on Rivanna): for i in range(1,2) is configured to capture 1 page of data per listing. The second number in the range() statement is not inclusive. If the researchers wanted to mine 10 categories, then they could change line 72 to: for i in range(1,6). This will collect up to 5 pages for each category: there are a maximum of 100 items per page, so (10 categories x 5 pages per category x 100 listings per page) should theoretically optimize the call limit.\n",
    "\n",
    "\n",
    "### eBay_datacollection.py\n",
    "This is the main script that contains the code to collect data from eBay. This script is well-commented and includes information on what certain code blocks do. \n",
    "\n",
    "### keys.env\n",
    "This file type stores your keys privately. These keys were obtained through eBay's developer's program. The keys were then used in the main python file to connect and collect data.\n",
    "\n",
    "### eBay_Slurm.slurm\n",
    "The file where we include parameters of running the automated script. \n",
    "\n",
    "### result.out\n",
    "Should print “Submitted batch job [number]\" when automated job is submitted correctly. \n",
    "\n",
    "### log.out\n",
    "Created when something goes wrong. It will specify the error from the main script. \n",
    "\n",
    "### eBaydata.db \n",
    "The database that contains the data. Data can be accessed from Accessingdata or through datasette. \n",
    "\n",
    "### Accessingdata.ipynb \n",
    "This file serves as another way to access and download the data in csv form. \n",
    "\n",
    "### ebay_data_4_27.csv\n",
    "Data collected from UVA Capstone team before automation is restarted in this nmicp space. Data is collected until 4-26-2022. \n",
    "\n",
    "### r_database_connection.R\n",
    "R file that connects to the database on Rivanna. This is another way to connect to the database to use the data in R for analysis. \n",
    "\n",
    "### SettingUpNewDatabase.ipynb\n",
    "This notebook is the code for setting up a new database for when we moved the data collection process from the capstone team space to the nmicp project space. This code can be used to set up a new database in a new project space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
